# readme

This study combines many variants of the You Only Look Once (YOLO) object detection method to computationally analyse the identification of people carrying dangerous things. The purpose of the study is to evaluate how well several YOLO versions—YOLOv5, YOLOv6, YOLOv7, and YOLOv8—identify people in real-time circumstances who may be carrying potentially harmful things.
The study dataset consists of photos that have been carefully selected to show people interacting with dangerous things in a variety of settings, including public spaces, airports, and other high-security regions. Bounding boxes were carefully added to the dataset to aid in model assessment and training. The project methodology uses transfer learning techniques to use prior information from large-scale datasets, training each iteration of YOLO on the annotated dataset. Standardised experimental settings are used during experimentation to guarantee equitable comparisons across YOLO variants. Each model's detection accuracy is evaluated using performance measures such as mean Average Precision (mAP), recall, F1 score, Intersection over Union (IoU), and precision.
The results of this computational investigation provide insightful information about the efficacy and efficiency of various YOLO variants in dangerous item and person detection tasks in real time. These observations can guide the creation and implementation of surveillance systems meant to improve public safety protocols in a range of contexts, such as busy transit areas, open gathering places, and high-security establishments.The project is to contribute to the development of computer vision technology and enhance security solutions by offering a thorough knowledge of the strengths and limits of YOLO models in identifying people carrying dangerous objects.
